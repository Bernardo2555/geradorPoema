{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generator.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bernardo2555/geradorPoema/blob/master/generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZuxbdKeb1Tm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "filename = \"C:/Users/username/Desktop/DL/poem_data3.txt\" #your own repository\n",
        "raw_text = open(filename, encoding=\"utf8\").read()\n",
        "raw_text = raw_text.lower() #converts all character to lower case for simplicity\n",
        "\n",
        "\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c,i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i,c) for i, c in enumerate(chars))\n",
        "\n",
        "n_chars = len(raw_text) # total #of characters in input file\n",
        "n_vocab = len(chars)    # total unique characters in input file\n",
        "\n",
        "max_len = 64   # length of a sentence that we use to train \n",
        "step = 3       # span of characters that we learn    \n",
        "sentence = []  # to store sentences to train\n",
        "next_char = [] # next character after the sentence\n",
        "\n",
        "for i in range(0, n_chars - max_len, step):\n",
        "    sentence.append(raw_text[i:i+max_len])\n",
        "    next_char.append(raw_text[i+max_len])\n",
        "    \n",
        "x = np.zeros((len(sentence), max_len, len(chars)),dtype=np.bool)\n",
        "y = np.zeros((len(sentence), len(chars)), dtype= np.bool)\n",
        "\n",
        "# assigns value 1 to corresponding row/column to represent sentences as boolean matrices\n",
        "for i, sentenc in enumerate(sentence):  # for each row/sentence\n",
        "    for t ,char in enumerate(sentenc):  # for each character in a row\n",
        "        x[i, t, char_to_int[char]] = 1\n",
        "    y[i, char_to_int[next_char[i]]] = 1\n",
        "    \n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape = (max_len, len(chars))))\n",
        "model.add(Dense(len(chars)))     #Final fully connected dense output layer \n",
        "model.add(Activation('softmax')) \n",
        "optimizer = RMSprop(lr= 0.01)    \n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = optimizer)\n",
        "\n",
        "\n",
        "# helper function to sample an index from a probability array\n",
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "  \n",
        "filepath = \"weights.hdfs\"\n",
        "print_callback = LambdaCallback()\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss',verbose=1, save_best_only=True, mode='min')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,patience=1, min_lr=0.001)\n",
        "callbacks = [print_callback, checkpoint, reduce_lr]\n",
        "\n",
        "model.fit(x, y, batch_size=128, epochs=10, callbacks=callbacks)\n",
        "\n",
        "def myGenerate(length_given, diversity_given):\n",
        "    input_taken = []  #user input text is stored here\n",
        "    sent = []           \n",
        "    input_taken = input('Enter first line of poem (min 40 chars):  ')\n",
        "    while(len(input_taken) < 40): # since the sentence length is predefined,\n",
        "        input_taken = []          # a minimum character or 'max_val' is expected\n",
        "        input_taken = input('..too short, please retype')\n",
        "    sent = input_taken[0:max_len] # first characters upto value of 'max_len'\n",
        "    gen = ''                      # is considered, to avoid input shape\n",
        "    gen += sent                   # compatibility problem\n",
        "    for i in range(length_given):\n",
        "        x_predicted = np.zeros((1, max_len, len(chars))) \n",
        "        for t, ch in enumerate(sent):  # converts the user entered text to \n",
        "            x_predicted[0, t, char_to_int[ch]] = 1 # a matrix 'x_predicted'\n",
        "        # and pass this matrix to model.predict() and stores return value in\n",
        "        predictions = model.predict(x_predicted, verbose = 0)[0] # predictions\n",
        "        # samples the character indices from helper function sample()\n",
        "        next_ind = sample(predictions, diversity_given)\n",
        "        next_ch = int_to_char[next_ind] # maps the index to characters\n",
        "        gen += next_ch                  # appends the generated character\n",
        "        sent = sent[1:] + next_ch       # appends to 'sent' to generate further\n",
        "    return gen\n",
        "\n",
        "print(myGenerate(500, 0.45))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}